{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil\n",
    "import albumentations as A\n",
    "import tensorflow.keras.optimizers as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = '../dataset/all/images'\n",
    "images_n_path = '../dataset/all/images_n'\n",
    "masks_path = '../dataset/all/masks'\n",
    "\n",
    "train_images_path = '../dataset/train/images'\n",
    "train_masks_path = '../dataset/train/masks'\n",
    "\n",
    "val_images_path = '../dataset/val/images'\n",
    "val_masks_path = '../dataset/val/masks'\n",
    "\n",
    "test_images_path = '../dataset/test/images'\n",
    "test_masks_path = '../dataset/test/masks'\n",
    "\n",
    "B=2\n",
    "N_CLASSES=2\n",
    "H,W =240,240\n",
    "SPLIT_SIZE = 32\n",
    "SPLIT_COUNT=H//SPLIT_SIZE\n",
    "N_EPOCHS=135\n",
    "BATCH_SIZE=32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:30px;\">Copy Positive image from main folder to train and validation folder</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_file_array = np.array(os.listdir(images_path))\n",
    "len_images = len(os.listdir(images_path))\n",
    "\n",
    "def move_pos_to_Train_Val(val_size = 0.05):\n",
    "    val_image_size = int(val_size*len_images)\n",
    "    val_random_index = np.random.choice(len_images,val_image_size,replace=False)\n",
    "\n",
    "    mask_train_val = np.ones(len_images,dtype=bool)\n",
    "    mask_train_val[val_random_index] = False\n",
    "\n",
    "    val_images_file = images_file_array[val_random_index]\n",
    "    train_images_file = images_file_array[mask_train_val]\n",
    "\n",
    "    for val_image_file in val_images_file:\n",
    "        shutil.copy2(os.path.join(images_path,str(val_image_file)),os.path.join(val_images_path,str(val_image_file)))\n",
    "        shutil.copy2(os.path.join(masks_path,str(val_image_file)),os.path.join(val_masks_path,str(val_image_file)))\n",
    "    \n",
    "    for train_image_file in train_images_file:\n",
    "        shutil.copy2(os.path.join(images_path,str(train_image_file)),os.path.join(train_images_path,str(train_image_file)))\n",
    "        shutil.copy2(os.path.join(masks_path,str(train_image_file)),os.path.join(train_masks_path,str(train_image_file)))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moveTo_Train_Val()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:30px;\">Copy Negative image from main folder to train and validation folder</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get count of positive and negative class in train and val\n",
    "def count_neg_pos_func(path):\n",
    "    count_neg_pos_class = {}\n",
    "    \n",
    "    for mask in os.listdir(path):\n",
    "        mask_file_path = os.path.join(path,mask)\n",
    "        mask_read = cv2.imread(mask_file_path,cv2.IMREAD_GRAYSCALE)\n",
    "        value = np.unique(mask_read)\n",
    "        if len(value)>1:\n",
    "            try:\n",
    "                count = count_neg_pos_class['pos']+1\n",
    "                count_neg_pos_class['pos'] = count\n",
    "            except:\n",
    "                count_neg_pos_class['pos'] = 1\n",
    "        elif len(value) == 1 and value[-1] == 0:\n",
    "            try:\n",
    "                count = count_neg_pos_class['neg']+1\n",
    "                count_neg_pos_class['neg'] = count\n",
    "            except:\n",
    "                count_neg_pos_class['neg'] = 1\n",
    "\n",
    "    return count_neg_pos_class\n",
    "\n",
    "# Move Negative Image \n",
    "def move_neg_to_train_val():\n",
    "    train_count_neg_pos_class = count_neg_pos_func(train_masks_path)\n",
    "    val_count_neg_pos_class = count_neg_pos_func(val_masks_path)\n",
    "\n",
    "    print(train_count_neg_pos_class)\n",
    "    print(val_count_neg_pos_class)\n",
    "\n",
    "    train_pos_count,train_neg_count = train_count_neg_pos_class['pos'],train_count_neg_pos_class['neg']\n",
    "    val_pos_count,val_neg_count = val_count_neg_pos_class['pos'],val_count_neg_pos_class['neg']\n",
    "\n",
    "    train_diff_class = np.abs(train_pos_count-train_neg_count)\n",
    "    val_diff_class = np.abs(val_pos_count-val_neg_count)\n",
    "     \n",
    "    images_n_file = os.listdir(images_n_path)\n",
    "    for idx in range(train_diff_class):\n",
    "        image_n_file_path = os.path.join(images_n_path,images_n_file[idx])\n",
    "        to_image_n_file_path = os.path.join(train_images_path,images_n_file[idx])\n",
    "\n",
    "        if not os.path.exists(to_image_n_file_path):\n",
    "            shutil.copy2(image_n_file_path,to_image_n_file_path)\n",
    "        else:\n",
    "            print(\"Train Negative File Exists\")\n",
    "\n",
    "    for idx in range(train_diff_class,train_diff_class+val_diff_class):\n",
    "        image_n_file_path = os.path.join(images_n_path,images_n_file[idx])\n",
    "        to_image_n_file_path = os.path.join(val_images_path,images_n_file[idx])\n",
    "\n",
    "        if not os.path.exists(to_image_n_file_path):\n",
    "            shutil.copy2(image_n_file_path,to_image_n_file_path)\n",
    "        else:\n",
    "            print(\"Val Negative File Exists\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move_neg_to_train_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_test(test_size = 0.01):\n",
    "    train_images_file = os.listdir(train_images_path)\n",
    "    len_test_size = int(len(train_images_file)*test_size)\n",
    "    random_index = np.random.choice(len(train_images_file),len_test_size,replace=False)\n",
    "    train_images_file_array = np.array(train_images_file)\n",
    "    \n",
    "    random_files = train_images_file_array[random_index]\n",
    "\n",
    "    for test_file in random_files:\n",
    "        train_image_path_file = os.path.join(train_images_path,test_file)\n",
    "        train_mask_path_file = os.path.join(train_masks_path,test_file)\n",
    "\n",
    "        test_image_path_file = os.path.join(test_images_path,test_file)\n",
    "        test_mask_path_file = os.path.join(test_masks_path,test_file)\n",
    "\n",
    "        shutil.move(train_image_path_file,test_image_path_file)\n",
    "        try:\n",
    "            shutil.move(train_mask_path_file,test_mask_path_file)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move_to_test()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>List Train and Validation Files name</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_file = os.listdir(train_images_path)\n",
    "train_masks_file = os.listdir(train_masks_path)\n",
    "\n",
    "val_images_file = os.listdir(val_images_path)\n",
    "val_masks_file = os.listdir(val_masks_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get Length train and validation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train_images = len(train_images_file)\n",
    "# 30614\n",
    "len_val_images = len(val_images_file)\n",
    "# 1611\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Print pixel value of masks</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e952bd3439a4191ad2dc72c2e2dee5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Mask Pixel Value', max=30290), Output()), _dom_classes=(…"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def printPixelMaskValue(index):\n",
    "    train_image_file = train_images_file[index]\n",
    "    train_image_file_path = os.path.join(train_masks_path,train_image_file)\n",
    "\n",
    "    mask = cv2.imread(train_image_file_path)\n",
    "    print(np.unique(mask,cv2.IMREAD_GRAYSCALE))\n",
    "\n",
    "index_slider = widgets.IntSlider(value=0,min=0,max=len(train_images_file)-1,step=1,description='Mask Pixel Value')\n",
    "widgets.interactive(printPixelMaskValue,index = index_slider)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Count negative and positive data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_neg_pos_func(path):\n",
    "    count_neg_pos_class = {}\n",
    "    \n",
    "    for image in os.listdir(path):\n",
    "        if os.path.exists(os.path.join(train_masks_path,image)):\n",
    "            mask_file_path = os.path.join(train_masks_path,image)\n",
    "            mask_read = cv2.imread(mask_file_path,cv2.IMREAD_GRAYSCALE)\n",
    "            value = np.unique(mask_read)\n",
    "            if len(value)>1:\n",
    "                try:\n",
    "                    count = count_neg_pos_class['pos']+1\n",
    "                    count_neg_pos_class['pos'] = count\n",
    "                except:\n",
    "                    count_neg_pos_class['pos'] = 1\n",
    "            elif len(value) == 1 and value[-1] == 0:\n",
    "                try:\n",
    "                    count = count_neg_pos_class['neg']+1\n",
    "                    count_neg_pos_class['neg'] = count\n",
    "                except:\n",
    "                    count_neg_pos_class['neg'] = 1\n",
    "        else:\n",
    "            try:\n",
    "                count = count_neg_pos_class['neg']+1\n",
    "                count_neg_pos_class['neg'] = count\n",
    "            except:\n",
    "                count_neg_pos_class['neg'] = 1\n",
    "\n",
    "    return count_neg_pos_class\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Show Images with defect</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e411e8b8a36d434295fe918b93f997ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Image Index:', max=30290), Output()), _dom_classes=('wid…"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def showImage(index):\n",
    "    train_image_file = train_images_file[index]\n",
    "    train_image_file_path = os.path.join(train_images_path,train_image_file)\n",
    "    train_mask_file_path = os.path.join(train_masks_path,train_image_file)\n",
    "\n",
    "\n",
    "    image = cv2.imread(train_image_file_path,cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    fig,ax = plt.subplots(1,2,figsize = (15,5))\n",
    "\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].set_title('Image  %s\\n%s'%(train_images_file[index],image.shape))\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    print('Mask Exists : %s'%os.path.exists(train_mask_file_path))\n",
    "    if os.path.exists(train_mask_file_path):\n",
    "        mask = cv2.imread(train_mask_file_path,cv2.IMREAD_GRAYSCALE)\n",
    "        ax[1].imshow(mask)\n",
    "        ax[1].set_title('Mask %s'%train_images_file[index])\n",
    "        ax[1].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "index_slider = widgets.IntSlider(value=0,min=0,max=len(train_images_file)-1,step=1,description='Image Index:')\n",
    "widgets.interactive(showImage,index = index_slider)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Show image with mask</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd06bf964b04c8292ffec2a2be01f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='Image Index:', max=30290), Output()), _dom_classes=('wid…"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def showImageWithMask(index):\n",
    "    fig,axis = plt.subplots(1,3,figsize = (15,5))\n",
    "\n",
    "    # Load image and mask file paths based on the provided index\n",
    "    train_image_file = train_images_file[index]\n",
    "    train_image_file_path = os.path.join(train_images_path,train_image_file)\n",
    "    train_mask_file_path = os.path.join(train_masks_path,train_image_file)\n",
    "\n",
    "    # Read the original image in grayscale\n",
    "    image = cv2.imread(train_image_file_path,cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Check if the mask file exists\n",
    "    if os.path.exists((train_mask_file_path)):\n",
    "        # Read the mask image in grayscale\n",
    "        mask_image = cv2.imread(train_mask_file_path,cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Find defect area with threshold\n",
    "        _,thresh = cv2.threshold(mask_image,0,5,cv2.THRESH_BINARY)\n",
    "\n",
    "        contours,_ = cv2.findContours(thresh,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        bboxes = []\n",
    "        for contour in contours:\n",
    "            bbox = cv2.boundingRect(contour)\n",
    "            bboxes.append(bbox)\n",
    "            cv2.rectangle(image,(bbox[0],bbox[1]),(bbox[0]+bbox[2],bbox[1]+bbox[3]),(255, 0, 0),2)\n",
    "        \n",
    "        # Draw contours on the original image in green color __ -1 mean all contours\n",
    "        cv2.drawContours(image,contours,-1,(0,1,0),2)\n",
    "\n",
    "        axis[1].imshow(mask_image)\n",
    "        axis[1].set_title('Mask')\n",
    "        \n",
    "        axis[2].imshow(thresh)\n",
    "        axis[2].set_title('Threshold Mask')\n",
    "\n",
    "        print('Boundry Boxes : ',bboxes)\n",
    "    \n",
    "    axis[0].imshow(image)\n",
    "    axis[0].set_title('Image & Contours\\n%s'%train_image_file)\n",
    "\n",
    "slider = widgets.IntSlider(value = 1,min = 0,max = len(train_images_file)-1,step=1,description='Image Index:')\n",
    "widgets.interactive(showImageWithMask,index = slider)\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Preparation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/train/masks\\0002cc93b_1.png\n"
     ]
    }
   ],
   "source": [
    "train_ims_paths = []\n",
    "train_masks_paths = []\n",
    "\n",
    "val_ims_paths = []\n",
    "val_masks_paths = []\n",
    "\n",
    "for image_file in train_images_file:\n",
    "    train_ims_paths.append(os.path.join(train_images_path,image_file))\n",
    "    if os.path.exists(os.path.join(train_masks_path,image_file)):\n",
    "        train_masks_paths.append(os.path.join(train_masks_path,image_file))\n",
    "    else:\n",
    "        train_masks_paths.append('None')\n",
    "\n",
    "for image_file in val_images_file:\n",
    "    val_ims_paths.append(os.path.join(val_images_path,image_file))\n",
    "    if os.path.exists(os.path.join(val_masks_path,image_file)):\n",
    "        val_masks_paths.append(os.path.join(val_masks_path,image_file))\n",
    "    else:\n",
    "        val_masks_paths.append('None')\n",
    "\n",
    "print(train_masks_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mask(mask_file):\n",
    "    bboxes = []\n",
    "    mask_file = mask_file.decode('utf8')\n",
    "\n",
    "    # Check if the mask is for training and the file exists in the training path\n",
    "    if mask_file == 'None':\n",
    "        return tf.convert_to_tensor(bboxes)\n",
    "        \n",
    "    mask = cv2.imread(mask_file,cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask,(H,W))\n",
    "    _,thresh = cv2.threshold(mask,0,np.unique(mask)[-1],cv2.THRESH_BINARY)\n",
    "    contours,_ = cv2.findContours(thresh,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Get image dimensions\n",
    "    width_pic = mask.shape[1]\n",
    "    height_pic = mask.shape[0]\n",
    "\n",
    "    for contour in contours:\n",
    "        x_center,y_center,width,height = cv2.boundingRect(contour)\n",
    "\n",
    "        # Normalize the bounding box coordinates\n",
    "        bbox = [\n",
    "            (x_center + (width / 2)) / width_pic,    # Center x normalized\n",
    "            (y_center + (height / 2)) / height_pic,  # Center y normalized\n",
    "            width / width_pic,              # Width normalized\n",
    "            height / height_pic,            # Height normalized\n",
    "            1.\n",
    "        ]\n",
    "        \n",
    "        bboxes.append(bbox)\n",
    "    return tf.convert_to_tensor(bboxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(bounding_boxes):\n",
    "    output_label = np.zeros((SPLIT_COUNT,SPLIT_COUNT,N_CLASSES+5))\n",
    "    for b in range(len(bounding_boxes)):\n",
    "        grid_x = bounding_boxes[...,b,0]*SPLIT_COUNT\n",
    "        grid_y = bounding_boxes[...,b,1]*SPLIT_COUNT\n",
    "\n",
    "        i = int(np.ceil(grid_x)-1)\n",
    "        j = int(np.ceil(grid_y)-1)\n",
    "\n",
    "        output_label[i,j] = [1,grid_x%1,grid_y%1,bounding_boxes[...,b,2],bounding_boxes[...,b,3],0.,1.]\n",
    "    \n",
    "    # For no defect\n",
    "    output_label[output_label[..., 0] == 0, 5] = 1.\n",
    "    \n",
    "\n",
    "    return tf.convert_to_tensor(output_label,dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = generate_output(preprocess_mask(os.path.join(train_masks_path,\"0002cc93b_1.png\").encode()))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Make dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_ims_paths,train_masks_paths))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_ims_paths,val_masks_paths))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Get Image and BBoxes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imbboxes(img_path,mask_pth):\n",
    "    img = tf.io.decode_png(tf.io.read_file(img_path),channels=3)\n",
    "    img = tf.cast(tf.image.resize(img,(H,W)),dtype=tf.float32)\n",
    "\n",
    "\n",
    "    bboxes = tf.numpy_function(func = preprocess_mask,inp=[mask_pth],Tout=tf.float32)\n",
    "\n",
    "    return img,bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(get_imbboxes)\n",
    "val_dataset = val_dataset.map(get_imbboxes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Check Image and BBoxes</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6f2b41f2754f18b8f6e98000f19559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Index Slider : ', max=30290), Output()), _dom_classes=('…"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_image_bboxes(index):  \n",
    "    for i,j in train_dataset.skip(index):\n",
    "        plt.title(\"Shape : %s\"%i.shape)\n",
    "        plt.imshow(i/255)\n",
    "        \n",
    "        if not j.shape[0]>0:\n",
    "            break\n",
    "\n",
    "        j_numpy = j.numpy()\n",
    "        x_center_norm = j_numpy[:,0]\n",
    "        y_center_norm = j_numpy[:,1]\n",
    "        width_normal = j_numpy[:,2]\n",
    "        height_normal = j_numpy[:,3]\n",
    "\n",
    "        x = x_center_norm*W\n",
    "        y = y_center_norm*H\n",
    "        width = width_normal*W\n",
    "        height = height_normal*H\n",
    "\n",
    "        x_min = x-(width/2)\n",
    "        y_min = y-(height/2)\n",
    "\n",
    "        x_max = x_min+width\n",
    "        y_max = y_min+height\n",
    "\n",
    "        for k in range(len(x_min)):\n",
    "            x_points = [x_min[k], x_max[k], x_max[k], x_min[k], x_min[k]]\n",
    "            y_points = [y_min[k], y_min[k], y_max[k], y_max[k], y_min[k]]\n",
    "\n",
    "            plt.plot(x_points, y_points, color=\"red\")\n",
    "        \n",
    "        break   \n",
    "    \n",
    "slider = widgets.IntSlider(min=0,max = len(train_images_file)-1,step=1,description = 'Index Slider : ')\n",
    "widgets.interactive(plot_image_bboxes,index = slider)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Albumentation augmented</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.Resize(H,W),\n",
    "    A.RandomCrop(width=np.random.randint(int(0.9*W),W),\n",
    "                 height=np.random.randint(int(0.9*H),H),p=0.5),\n",
    "    A.RandomScale(scale_limit=0.1,interpolation=cv2.INTER_LANCZOS4,p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Resize(H,W)\n",
    "],bbox_params=A.BboxParams(format='yolo',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_albument(image,bboxes):\n",
    "    augmented = transform(image = image,bboxes = bboxes)\n",
    "    image = augmented['image']\n",
    "    bboxes = augmented['bboxes']\n",
    "\n",
    "    return [tf.convert_to_tensor(image,dtype=tf.float32),\n",
    "            tf.convert_to_tensor(bboxes,dtype=tf.float32)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(image,bboxes):\n",
    "    aug = tf.numpy_function(aug_albument,inp=[image,bboxes],Tout=(tf.float32,tf.float32))\n",
    "    return aug[0],aug[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(process_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Check image and Bboxes after Transform</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f026a9e9f4b54befb514e88b08b3aca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='Image Index:', max=30290), Output()), _dom_classes=('wid…"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_image_bboxes_after_transform(index):\n",
    "    for i,j in train_dataset.skip(index):\n",
    "        plt.title(i.shape)\n",
    "        plt.imshow(i/255)\n",
    "\n",
    "        if not j.shape[0]>0:\n",
    "            print('p')\n",
    "            break\n",
    "\n",
    "        print(j.shape)\n",
    "        x_center_norm = j[...,0]\n",
    "        y_center_norm = j[...,1]\n",
    "        width_norm = j[...,2]\n",
    "        height_norm = j[...,3]\n",
    "\n",
    "        min_x_norm = x_center_norm-(width_norm/2)\n",
    "        min_y_norm = y_center_norm-(height_norm/2)\n",
    "        max_x_norm = min_x_norm+width_norm\n",
    "        max_y_norm = min_y_norm+height_norm\n",
    "\n",
    "        min_x = min_x_norm*W\n",
    "        max_x = max_x_norm*W\n",
    "        min_y = min_y_norm*H\n",
    "        max_y = max_y_norm*H\n",
    "\n",
    "\n",
    "        for rect_idx in range(len(min_x_norm)):\n",
    "            plt.plot([min_x[rect_idx],min_x[rect_idx]],[min_y[rect_idx],max_y[rect_idx]],'r')\n",
    "            plt.plot([min_x[rect_idx],max_x[rect_idx]],[min_y[rect_idx],min_y[rect_idx]],'r')\n",
    "            plt.plot([max_x[rect_idx],max_x[rect_idx]],[min_y[rect_idx],max_y[rect_idx]],'r')\n",
    "            plt.plot([min_x[rect_idx],max_x[rect_idx]],[max_y[rect_idx],max_y[rect_idx]],'r')\n",
    "\n",
    "        break\n",
    "\n",
    "index_slider = widgets.IntSlider(value=1,min=0,max=len(train_images_file)-1,step=1,description='Image Index:')\n",
    "widgets.interactive(plot_image_bboxes_after_transform,index = index_slider)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Change saturation color and like these for train dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_augment(img,y):\n",
    "    img = tf.image.random_brightness(img,max_delta=50.)\n",
    "    img = tf.image.random_saturation(img,lower = 0.5,upper=1.5)\n",
    "    img = tf.image.random_contrast(img,lower=0.5,upper=1.5)\n",
    "    img = tf.clip_by_value(img,0,255)\n",
    "    labels = tf.numpy_function(generate_output,inp=[y],Tout=(tf.float32))\n",
    "    img = tf.cast(img,dtype = tf.float32)\n",
    "    return img,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img,y):\n",
    "    img = tf.cast(tf.image.resize(img, size=[H, W]), dtype=tf.float32)\n",
    "    labels = tf.numpy_function(func = generate_output,inp=[y],Tout=(tf.float32))\n",
    "\n",
    "    return img,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(preprocess_augment)\n",
    "val_dataset = val_dataset.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in train_dataset:\n",
    "#     print(y.shape)\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset=(\n",
    "  val_dataset.\n",
    "  batch(BATCH_SIZE).\n",
    "  prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=(\n",
    "  train_dataset.\n",
    "  batch(BATCH_SIZE,drop_remainder=True).\n",
    "  prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FILTERS = 512\n",
    "OUTPUT_DIM = B*5+N_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.efficientnet.EfficientNetB1(\n",
    "    weights='imagenet',\n",
    "    input_shape=(H,W,3),\n",
    "    include_top=False\n",
    ")\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb1 (Functional)  (None, 8, 8, 1280)       6575239   \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 8, 8, 512)         5898752   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 8, 8, 512)        2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 8, 8, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8, 8, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               16777728  \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 588)               301644    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 12)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,640,979\n",
      "Trainable params: 30,061,644\n",
      "Non-trainable params: 6,579,335\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.Conv2D(NUM_FILTERS,(3,3),padding='same',kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "\n",
    "    tf.keras.layers.Conv2D(NUM_FILTERS,(3,3),padding='same',kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "\n",
    "    tf.keras.layers.Conv2D(NUM_FILTERS,(3,3),padding='same',kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "\n",
    "    tf.keras.layers.Conv2D(NUM_FILTERS,(3,3),padding = 'same',kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(NUM_FILTERS,kernel_initializer = 'he_normal'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(alpha = 0.1),\n",
    "\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(SPLIT_COUNT*SPLIT_COUNT*OUTPUT_DIM,activation='sigmoid'),\n",
    "\n",
    "    tf.keras.layers.Reshape((SPLIT_COUNT,SPLIT_COUNT,OUTPUT_DIM))\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxes1,boxes2):\n",
    "    box1_t = tf.stack([boxes1[...,0]-boxes1[...,2]/2,\n",
    "                        boxes1[...,1]-boxes1[...,3]/2,\n",
    "                        boxes1[...,0]+boxes1[...,2]/2,\n",
    "                        boxes1[...,3]+boxes1[...,3]/2],axis=-1)\n",
    "\n",
    "    box2_t = tf.stack([boxes1[...,0]-boxes2[...,2]/2,\n",
    "                          boxes2[...,1]-boxes2[...,3]/2,\n",
    "                          boxes2[...,0]+boxes2[...,2]/2,\n",
    "                          boxes2[...,1]+boxes2[...,3]/2],axis=-1)\n",
    "    \n",
    "    lu = tf.maximum(boxes1[...,:2],boxes2[...,:2])\n",
    "    rd = tf.minimum(boxes1[...,2:],boxes2[...,2:])\n",
    "\n",
    "    intersection = tf.maximum(0.0,rd-lu)\n",
    "    inter_square = intersection[...,0]*intersection[...,1]\n",
    "\n",
    "    square_1 = boxes1[...,2]*boxes1[...,3]\n",
    "    square_2 = boxes2[...,2]*boxes2[...,3]\n",
    "\n",
    "    union_square = tf.maximum(square_1+square_2-inter_square,1e-10)\n",
    "    return tf.clip_by_value(inter_square/union_square,0.0,1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(y,x):\n",
    "    return tf.reduce_sum(tf.square(y-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imput shape : y_True(BATCH_SIZE , SPLIT_COUNT , SPLIT_COUNT , N_CLASSES+5)\n",
    "# imput shape : y_pred(BATCH_SIZE , SPLIT_COUNT , SPLIT_COUNT , N_CLASSES+5*B)\n",
    "def yolo_loss(y_true,y_pred):\n",
    "    target = y_true[...,0]\n",
    "    \n",
    "    y_true_extract = tf.gather_nd(y_true,tf.where(target == 1))\n",
    "    y_pred_extract = tf.gather_nd(y_pred,tf.where(target == 1))\n",
    "\n",
    "    rescaler = tf.where(target == 1)*32\n",
    "\n",
    "    upscaler_1 = tf.concat([rescaler[:,1:],tf.zeros((len(rescaler),2),dtype=tf.int64)],axis=-1)\n",
    "\n",
    "    target_upscaler_2 = tf.repeat([[float(SPLIT_SIZE),float(SPLIT_SIZE),float(H),float(W)]],repeats=[len(rescaler)],axis=0) * \\\n",
    "                                    tf.cast(y_true_extract[...,1:5],dtype=tf.float32)\n",
    "    pred_1_upscaler_2 = tf.repeat([[float(SPLIT_SIZE),float(SPLIT_SIZE),float(H),float(W)]],repeats=[len(rescaler)],axis=0) * \\\n",
    "                                    tf.cast(y_pred_extract[...,1:5],dtype=tf.float32)\n",
    "    pred_2_upscaler_2 = tf.repeat([[float(SPLIT_SIZE),float(SPLIT_SIZE),float(H),float(W)]],repeats=[len(rescaler)],axis=0) * \\\n",
    "                                    tf.cast(y_pred_extract[...,5:9],dtype=tf.float32)\n",
    "    \n",
    "    target_orig = tf.cast(upscaler_1,tf.float32)+target_upscaler_2\n",
    "    pred_1_orig = tf.cast(upscaler_1,tf.float32)+pred_1_upscaler_2\n",
    "    pred_2_orig = tf.cast(upscaler_1,tf.float32)+pred_2_upscaler_2\n",
    "\n",
    "    mask_bool = tf.greater(compute_iou(target_orig,pred_1_orig),compute_iou(target_orig,pred_2_orig))\n",
    "    mask_int = tf.cast(mask_bool,tf.int32)\n",
    "\n",
    "    conf_pred_1 = y_pred_extract[:,0]\n",
    "    conf_pred_2 = y_pred_extract[:,5]\n",
    "\n",
    "    conf_preds = tf.stack((conf_pred_1,conf_pred_2),axis=-1)\n",
    "    mask_index = tf.stack((tf.range(len(rescaler)),mask_int),axis = -1)\n",
    "\n",
    "    obj_pred = tf.gather_nd(conf_preds,mask_index)\n",
    "    object_loss = difference(tf.cast(tf.ones(len(rescaler)),dtype = tf.float32),\n",
    "                    tf.cast(obj_pred,tf.float32))\n",
    "    \n",
    "    \n",
    "    \n",
    "    '-------------------------------------------------------------------------------'\n",
    "\n",
    "    y_pred_extract = tf.gather_nd(y_pred,tf.where(target == 0))\n",
    "    y_target_extract = tf.zeros(len(y_pred_extract),dtype = tf.float32)\n",
    "\n",
    "    no_object_loss_1 = difference(y_target_extract,y_pred_extract[...,0])\n",
    "    no_object_loss_2 = difference(y_target_extract,y_pred_extract[...,5])\n",
    "\n",
    "    no_object_loss = no_object_loss_1+no_object_loss_2\n",
    "\n",
    "    '-------------------------------------------------------------------------------'\n",
    "\n",
    "    y_pred_label = tf.reshape(y_pred[...,10:],(-1,2))\n",
    "    y_true_label = tf.reshape(y_true[...,5:],(-1,2))\n",
    "    \n",
    "    class_loss = difference(y_true_label,y_pred_label)\n",
    "\n",
    "    '-------------------------------------------------------------------------------'    \n",
    "\n",
    "    bbox_target = tf.gather_nd(y_true[...,1:5],tf.where(target == 1))\n",
    "    bbox_pred_1 = tf.gather_nd(y_pred[...,1:5],tf.where(target == 1))\n",
    "    bbox_pred_2 = tf.gather_nd(y_pred[...,6:10],tf.where(target == 1))\n",
    "    \n",
    "    bbox_pred = tf.stack((bbox_pred_1,bbox_pred_2),axis=1)\n",
    "    obj_bbox_pred = tf.gather_nd(bbox_pred,mask_index)\n",
    "\n",
    "    center_loss = difference(bbox_target[...,:2],obj_bbox_pred[...,:2])\n",
    "    size_loss = difference(tf.math.sqrt(tf.math.abs(bbox_target[...,2:])),tf.math.sqrt(tf.math.abs(obj_bbox_pred[...,2:])))\n",
    "\n",
    "    bbox_loss = center_loss+size_loss\n",
    "\n",
    "    lambda_no_obj = 0.5\n",
    "    lambda_coord = 5.0\n",
    "\n",
    "    loss = object_loss + (lambda_no_obj*no_object_loss) + (lambda_coord*bbox_loss) + class_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = tf.random.uniform((1,3,3,12),minval=0,maxval = 1)\n",
    "y_true = \\\n",
    "   [\n",
    "   [\n",
    "        [[0.0, 0.  , 0.  , 0.  , 0.  , 1.0, 0.0],   # Grid (0, 0)\n",
    "         [1.0, 0.56, 0.89, 0.67, 0.24, 0.0, 1.0],   # Grid (0, 1)\n",
    "         [0.0, 0.  , 0.  , 0.  , 0.  , 1.0, 0.0]],  # Grid (0, 2)\n",
    "\n",
    "        [[0.0, 0.34, 0.67, 0.23, 0.45, 1.0, 0.0],   # Grid (1, 0)\n",
    "         [0.0, 0.  , 0.  , 0.  , 0.  , 1.0, 0.0],   # Grid (1, 1)\n",
    "         [1.0, 0.78, 0.56, 0.12, 0.89, 0.0, 1.0]],  # Grid (1, 2)\n",
    "\n",
    "        [[1.0, 0.45, 0.34, 0.56, 0.67, 1.0, 1.0],   # Grid (2, 0)\n",
    "         [0.0, 0.  , 0.  , 0.  , 0.  , 1.0, 0.0],   # Grid (2, 1)\n",
    "         [1.0, 0.67, 0.89, 0.23, 0.56, 1.0, 1.0]]   # Grid (2, 2)\n",
    "   ]\n",
    "   ] \n",
    "\n",
    "y_pred = \\\n",
    "    [\n",
    "    [\n",
    "        [[0.05, 0.02, 0.01, 0.03, 0.02, 0.15, 0.02, 0.21, 0.23, 0.52, 0.85, 0.15],       # Grid (0, 0)\n",
    "         [0.95, 0.58, 0.87, 0.68, 0.22, 0.75, 0.58, 0.67, 0.78, 0.42, 0.15, 0.95],       # Grid (0, 1)\n",
    "         [0.07, 0.03, 0.02, 0.01, 0.14, 0.17, 0.03, 0.02, 0.01, 0.24, 0.88, 0.12]],      # Grid (0, 2)\n",
    "\n",
    "        [[0.08, 0.36, 0.66, 0.25, 0.44, 0.38, 0.36, 0.76, 0.25, 0.74, 0.78, 0.22],       # Grid (1, 0)\n",
    "         [0.02, 0.01, 0.0 , 0.0 , 0.03, 0.12, 0.01, 0.32 , 0.0, 0.53, 0.85, 0.15],       # Grid (1, 1)\n",
    "         [0.85, 0.76, 0.58, 0.13, 0.84, 0.75, 0.56, 0.38, 0.13, 0.44, 0.12, 0.88]],      # Grid (1, 2)\n",
    "\n",
    "        [[0.92, 0.44, 0.35, 0.55, 0.65, 0.62, 0.34, 0.25, 0.55, 0.75, 0.72, 0.85],       # Grid (2, 0)\n",
    "         [0.06, 0.02, 0.01, 0.0 , 0.0 , 0.16, 0.02, 0.01, 0.0 , 0.0 , 0.96, 0.14],       # Grid (2, 1)\n",
    "         [0.88, 0.68, 0.84, 0.22, 0.57, 0.83, 0.68, 0.84, 0.22, 0.47, 0.65, 0.88]]       # Grid (2, 2)\n",
    "    ]\n",
    "    ]\n",
    "# print(yolo_loss(tf.constant(y_true),tf.constant(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../callback/detect_defect.h5'\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=file_path,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch,lr):\n",
    "    if epoch < 40:\n",
    "        return 1e-3\n",
    "    elif epoch>=40 and epoch<80:\n",
    "        return 5e-4\n",
    "    else:\n",
    "        return 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = yolo_loss,\n",
    "    optimizer=optim.Adam(learning_rate = 1e-3)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../callback/detect_defect.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.fit(\n",
    "#     train_dataset,\n",
    "#     validation_data=val_dataset,\n",
    "#     verbose=1,\n",
    "#     epochs=50,\n",
    "#     callbacks=[lr_callback,callback]\n",
    "#     )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Test Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = '../dataset/test/images/'\n",
    "test_images_file = os.listdir(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model_test(index):\n",
    "    filename = test_images_file[index]\n",
    "    test_path=test_image_path+filename\n",
    "\n",
    "    img=cv2.resize(cv2.imread(test_path),(H,W))\n",
    "\n",
    "    image=tf.io.decode_jpeg(tf.io.read_file(test_path))\n",
    "    image=tf.image.resize(image, [H,W])\n",
    "\n",
    "    output=model.predict(np.expand_dims(image, axis = 0))\n",
    "\n",
    "    THRESH=.25\n",
    "\n",
    "    object_positions=tf.concat(\n",
    "        [tf.where(output[...,0]>=THRESH),tf.where(output[...,5]>=THRESH)],axis=0)\n",
    "    selected_output=tf.gather_nd(output,object_positions)\n",
    "    final_boxes=[]\n",
    "    final_scores=[]\n",
    "\n",
    "    for i,pos in enumerate(object_positions):\n",
    "        for j in range(2):      \n",
    "            if selected_output[i][j*5]>THRESH:\n",
    "                output_box=tf.cast(output[pos[0]][pos[1]][pos[2]][(j*5)+1:(j*5)+5],dtype=tf.float32)\n",
    "\n",
    "                x_centre=(tf.cast(pos[1],dtype=tf.float32)+output_box[0])*32\n",
    "                y_centre=(tf.cast(pos[2],dtype=tf.float32)+output_box[1])*32\n",
    "\n",
    "                x_width,y_height=tf.math.abs(H*output_box[2]),tf.math.abs(W*output_box[3])\n",
    "                \n",
    "                x_min,y_min=int(x_centre-(x_width/2)),int(y_centre-(y_height/2))\n",
    "                x_max,y_max=int(x_centre+(x_width/2)),int(y_centre+(y_height/2))\n",
    "\n",
    "                if(x_min<=0):x_min=0\n",
    "                if(y_min<=0):y_min=0\n",
    "                if(x_max>=W):x_max=W\n",
    "                if(y_max>=H):y_max=H\n",
    "                final_boxes.append(\n",
    "                    [x_min,y_min,x_max,y_max])\n",
    "                final_scores.append(round(float(selected_output[i][j*5]),3))\n",
    "\n",
    "    final_boxes=np.array(final_boxes)\n",
    "\n",
    "    if final_boxes.shape[0]>0:\n",
    "        nms_boxes=final_boxes[...,0:4]\n",
    "        \n",
    "        nms_output=tf.image.non_max_suppression(\n",
    "            nms_boxes,\n",
    "            final_scores,\n",
    "            max_output_size=100,\n",
    "            iou_threshold=0.2,\n",
    "            score_threshold=float('-inf')\n",
    "        )\n",
    "        \n",
    "        for i in nms_output:\n",
    "            cv2.rectangle(\n",
    "                img,\n",
    "                (int(final_boxes[i][0]),int(final_boxes[i][1])),\n",
    "                (int(final_boxes[i][2]),int(final_boxes[i][3])),(0,0,255),2)\n",
    "            \n",
    "            text ='Score : '+str(final_scores[i])\n",
    "            size_text = pos_text = cv2.getTextSize(text,cv2.FONT_HERSHEY_COMPLEX_SMALL,0.8,1)[0]\n",
    "            \n",
    "            pos_text = [int(final_boxes[i][0]),int(final_boxes[i][1])]\n",
    "\n",
    "            if size_text[0]+int(final_boxes[i][0]) > W :pos_text[0] = pos_text[0]-(size_text[0]+int(final_boxes[i][0])-W)\n",
    "            if np.abs(size_text[1]-int(final_boxes[i][1])) < 0 :pos_text[1] = size_text[1]\n",
    "\n",
    "            cv2.putText(\n",
    "                img,\n",
    "                text,\n",
    "                pos_text,\n",
    "                cv2.FONT_HERSHEY_COMPLEX_SMALL,0.8,(2,225,155),1\n",
    "                )\n",
    "\n",
    "\n",
    "    plt.figure(figsize = (8,8))\n",
    "    if os.path.exists(os.path.join(test_masks_path,filename)):\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(img)\n",
    "        \n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(cv2.imread(os.path.join(test_masks_path,filename),cv2.IMREAD_GRAYSCALE))\n",
    "\n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5658163aee4141608408dac24ce23aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=305), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slider = widgets.IntSlider(min = 0,max = len(os.listdir(test_image_path)),step=1,value=0)\n",
    "widgets.interactive(model_test,index = slider)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_django_exe-NG3i0hEm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
